2024-05-26 21:28:25,027 INFO    MainThread:28229 [wandb_setup.py:_flush():76] Current SDK version is 0.17.0
2024-05-26 21:28:25,027 INFO    MainThread:28229 [wandb_setup.py:_flush():76] Configure stats pid to 28229
2024-05-26 21:28:25,027 INFO    MainThread:28229 [wandb_setup.py:_flush():76] Loading settings from /Users/lisa/.config/wandb/settings
2024-05-26 21:28:25,027 INFO    MainThread:28229 [wandb_setup.py:_flush():76] Loading settings from /Users/lisa/Documents/atari/wandb/settings
2024-05-26 21:28:25,027 INFO    MainThread:28229 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-05-26 21:28:25,027 INFO    MainThread:28229 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-05-26 21:28:25,027 INFO    MainThread:28229 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'compare_dqn.py', 'program_abspath': '/Users/lisa/Documents/atari/compare_dqn.py', 'program': '/Users/lisa/Documents/atari/compare_dqn.py'}
2024-05-26 21:28:25,027 INFO    MainThread:28229 [wandb_init.py:_log_setup():520] Logging user logs to /Users/lisa/Documents/atari/wandb/offline-run-20240526_212825-gztqhy6r/logs/debug.log
2024-05-26 21:28:25,028 INFO    MainThread:28229 [wandb_init.py:_log_setup():521] Logging internal logs to /Users/lisa/Documents/atari/wandb/offline-run-20240526_212825-gztqhy6r/logs/debug-internal.log
2024-05-26 21:28:25,028 INFO    MainThread:28229 [wandb_init.py:init():560] calling init triggers
2024-05-26 21:28:25,028 INFO    MainThread:28229 [wandb_init.py:init():567] wandb.init called with sweep_config: {}
config: {}
2024-05-26 21:28:25,028 INFO    MainThread:28229 [wandb_init.py:init():610] starting backend
2024-05-26 21:28:25,028 INFO    MainThread:28229 [wandb_init.py:init():614] setting up manager
2024-05-26 21:28:25,032 INFO    MainThread:28229 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2024-05-26 21:28:25,032 INFO    MainThread:28229 [wandb_init.py:init():622] backend started and connected
2024-05-26 21:28:25,039 INFO    MainThread:28229 [wandb_init.py:init():711] updated telemetry
2024-05-26 21:28:25,039 INFO    MainThread:28229 [wandb_init.py:init():744] communicating run to backend with 90.0 second timeout
2024-05-26 21:28:25,041 INFO    MainThread:28229 [wandb_init.py:init():795] starting run threads in backend
2024-05-26 21:28:25,598 INFO    MainThread:28229 [wandb_run.py:_console_start():2374] atexit reg
2024-05-26 21:28:25,598 INFO    MainThread:28229 [wandb_run.py:_redirect():2229] redirect: wrap_raw
2024-05-26 21:28:25,598 INFO    MainThread:28229 [wandb_run.py:_redirect():2294] Wrapping output streams.
2024-05-26 21:28:25,598 INFO    MainThread:28229 [wandb_run.py:_redirect():2319] Redirects installed.
2024-05-26 21:28:25,599 INFO    MainThread:28229 [wandb_init.py:init():838] run started, returning control to user process
2024-05-26 21:28:25,947 INFO    MainThread:28229 [wandb_run.py:_tensorboard_callback():1538] tensorboard callback: ./dqn_tensorboard/DQN_13, True
2024-05-26 21:28:25,949 INFO    MainThread:28229 [wandb_watch.py:watch():51] Watching
2024-05-26 21:28:25,950 INFO    MainThread:28229 [wandb_run.py:_config_callback():1376] config_cb None None {'algo': 'DQN', 'policy_class': "<class 'stable_baselines3.dqn.policies.DQNPolicy'>", 'device': 'mps', 'verbose': 1, 'policy_kwargs': '{}', 'num_timesteps': 0, '_total_timesteps': 1000000, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1716751705941656000, 'learning_rate': 0.0001, 'tensorboard_log': './dqn_tensorboard/', '_last_obs': '[[  0 130 189 196 255   0 255   0   0   0   0   0   0   0   5   5   5   5\n    5 133   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n    0   0   7   7   7   7   7   7  88  88  88  88  88  88 180  76   0 254\n    1 255 255  17   0 252  12   1  20 168  88 251   1  20 168  88 127  15\n  254  15 254  73 255  88 251  88 251  88 251  88 251  88 251   0 251   7\n  253  88 252  88 255  88   0  88 255  88 255  88 255   0 255  20 168   0\n    0   0 214  28   6  30 233   0   0   0   0   0   0   0   0   0 255 255\n  226 245]]', '_last_episode_starts': '[ True]', '_last_original_obs': 'None', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x104fb27d0>', '_vec_normalize_env': 'None', 'observation_space': 'Box(0, 255, (128,), uint8)', 'action_space': 'Discrete(18)', 'n_envs': 1, 'buffer_size': 1000000, 'batch_size': 32, 'learning_starts': 100, 'tau': 1.0, 'gamma': 0.99, 'gradient_steps': 1, 'optimize_memory_usage': 'False', 'replay_buffer': '<stable_baselines3.common.buffers.ReplayBuffer object at 0x16d6c60d0>', 'replay_buffer_class': "<class 'stable_baselines3.common.buffers.ReplayBuffer'>", 'replay_buffer_kwargs': '{}', '_episode_storage': 'None', 'train_freq': "TrainFreq(frequency=4, unit=<TrainFrequencyUnit.STEP: 'step'>)", 'use_sde_at_warmup': 'False', 'exploration_initial_eps': 1.0, 'exploration_final_eps': 0.05, 'exploration_fraction': 0.1, 'target_update_interval': 10000, '_n_calls': 0, 'max_grad_norm': 10, 'exploration_rate': 0.0, 'lr_schedule': '<function get_schedule_fn.<locals>.<lambda> at 0x31ae28a40>', 'policy': 'DQNPolicy(\n  (q_net): QNetwork(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (q_net): Sequential(\n      (0): Linear(in_features=128, out_features=64, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=64, out_features=18, bias=True)\n    )\n  )\n  (q_net_target): QNetwork(\n    (features_extractor): FlattenExtractor(\n      (flatten): Flatten(start_dim=1, end_dim=-1)\n    )\n    (q_net): Sequential(\n      (0): Linear(in_features=128, out_features=64, bias=True)\n      (1): ReLU()\n      (2): Linear(in_features=64, out_features=64, bias=True)\n      (3): ReLU()\n      (4): Linear(in_features=64, out_features=18, bias=True)\n    )\n  )\n)', 'q_net': 'QNetwork(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (q_net): Sequential(\n    (0): Linear(in_features=128, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=18, bias=True)\n  )\n)', 'q_net_target': 'QNetwork(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (q_net): Sequential(\n    (0): Linear(in_features=128, out_features=64, bias=True)\n    (1): ReLU()\n    (2): Linear(in_features=64, out_features=64, bias=True)\n    (3): ReLU()\n    (4): Linear(in_features=64, out_features=18, bias=True)\n  )\n)', 'batch_norm_stats': '[]', 'batch_norm_stats_target': '[]', 'exploration_schedule': '<function get_linear_fn.<locals>.func at 0x31ae28e00>', '_logger': '<stable_baselines3.common.logger.Logger object at 0x16d6c6a90>'}
2024-05-26 22:13:12,416 INFO    MainThread:28229 [sb3.py:save_model():153] Saving model checkpoint to ./models/dqn_ram/model.zip
2024-05-26 22:13:12,425 INFO    MainThread:28229 [wandb_run.py:_finish():2103] finishing run lisa-stuch/RL_DQN_RAM/gztqhy6r
2024-05-26 22:13:12,425 INFO    MainThread:28229 [wandb_run.py:_atexit_cleanup():2343] got exitcode: 0
2024-05-26 22:13:12,425 INFO    MainThread:28229 [wandb_run.py:_restore():2326] restore
2024-05-26 22:13:12,425 INFO    MainThread:28229 [wandb_run.py:_restore():2332] restore done
2024-05-26 22:13:19,476 INFO    MainThread:28229 [wandb_run.py:_footer_history_summary_info():3994] rendering history
2024-05-26 22:13:19,480 INFO    MainThread:28229 [wandb_run.py:_footer_history_summary_info():4026] rendering summary
